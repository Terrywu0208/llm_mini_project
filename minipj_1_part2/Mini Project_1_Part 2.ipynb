{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install datasets sentence_transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create your API token from your Hugging Face Account. Make sure to save it in text file or notepad for future use.\n",
    "# Will need to add it once per section\n",
    "from huggingface_hub import login\n",
    "login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, InputExample, losses\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "from datasets import load_dataset\n",
    "import time\n",
    "\n",
    "class TextSimilarityModel:\n",
    "    def __init__(self, corpus_name, rel_name, model_name='all-MiniLM-L6-v2', top_k=10):\n",
    "        \"\"\"\n",
    "        Initialize the model with datasets and pre-trained sentence transformer.\n",
    "        \"\"\"\n",
    "        self.model = SentenceTransformer(model_name)\n",
    "        self.corpus_name = corpus_name\n",
    "        self.rel_name = rel_name\n",
    "        self.top_k = top_k\n",
    "        self.load_data()\n",
    "\n",
    "\n",
    "    def load_data(self):\n",
    "        \"\"\"\n",
    "        Load and filter datasets based on test queries and documents.\n",
    "        \"\"\"\n",
    "        # Load query and document datasets\n",
    "        dataset_queries = load_dataset(self.corpus_name, \"queries\")\n",
    "        dataset_docs = load_dataset(self.corpus_name, \"corpus\")\n",
    "\n",
    "        # Extract queries and documents\n",
    "        self.queries = dataset_queries[\"queries\"][\"text\"]\n",
    "        self.query_ids = dataset_queries[\"queries\"][\"_id\"]\n",
    "        self.documents = dataset_docs[\"corpus\"][\"text\"]\n",
    "        self.document_ids = dataset_docs[\"corpus\"][\"_id\"]\n",
    "\n",
    "                \n",
    "        # Filter queries and documents and build relevant queries and documents mapping based on test set\n",
    "        test_qrels = load_dataset(self.rel_name)[\"test\"]\n",
    "        self.filtered_test_query_ids = set(test_qrels[\"query-id\"])\n",
    "        self.filtered_test_doc_ids = set(test_qrels[\"corpus-id\"])\n",
    "\n",
    "        self.test_queries = [q for qid, q in zip(self.query_ids, self.queries) if qid in self.filtered_test_query_ids]\n",
    "        self.test_query_ids = [qid for qid in self.query_ids if qid in self.filtered_test_query_ids]\n",
    "        self.test_documents = [doc for did, doc in zip(self.document_ids, self.documents) if did in self.filtered_test_doc_ids]\n",
    "        self.test_document_ids = [did for did in self.document_ids if did in self.filtered_test_doc_ids]\n",
    "\n",
    "        self.test_query_id_to_relevant_doc_ids = {qid: [] for qid in self.test_query_ids}\n",
    "        for qid, doc_id in zip(test_qrels[\"query-id\"], test_qrels[\"corpus-id\"]):\n",
    "            if qid in self.test_query_id_to_relevant_doc_ids:\n",
    "                self.test_query_id_to_relevant_doc_ids[qid].append(doc_id)\n",
    "                \n",
    "        ## Code Below this is used for creating the training set \n",
    "        # Build query and document id to text mapping\n",
    "        self.query_id_to_text = {query_id:query for query_id, query in zip(self.query_ids, self.queries)}\n",
    "        self.document_id_to_text = {document_id:document for document_id, document in zip(self.document_ids, self.documents)}\n",
    "\n",
    "        # Build relevant queries and documents mapping based on train set\n",
    "        train_qrels = load_dataset(self.rel_name)[\"train\"]\n",
    "        self.train_query_id_to_relevant_doc_ids = {qid: [] for qid in train_qrels[\"query-id\"]}\n",
    "\n",
    "        for qid, doc_id in zip(train_qrels[\"query-id\"], train_qrels[\"corpus-id\"]):\n",
    "            if qid in self.train_query_id_to_relevant_doc_ids:\n",
    "                # Append the document ID to the relevant doc mapping\n",
    "                self.train_query_id_to_relevant_doc_ids[qid].append(doc_id)\n",
    "        \n",
    "        # Filter queries and documents and build relevant queries and documents mapping based on validation set  \n",
    "        #TODO Put your code here. \n",
    "         ###########################################################################\n",
    "       \n",
    "        ###########################################################################\n",
    "        \n",
    "\n",
    "    #Task 1: Encode Queries and Documents (10 Pts)\n",
    "\n",
    "    def encode_with_glove(self, glove_file_path: str, sentences: list[str]) -> list[np.ndarray]:\n",
    "\n",
    "        \"\"\"\n",
    "        # Inputs:\n",
    "            - glove_file_path (str): Path to the GloVe embeddings file (e.g., \"glove.6B.50d.txt\").\n",
    "            - sentences (list[str]): A list of sentences to encode.\n",
    "\n",
    "        # Output:\n",
    "            - list[np.ndarray]: A list of sentence embeddings \n",
    "            \n",
    "        (1) Encodes sentences by averaging GloVe 50d vectors of words in each sentence.\n",
    "        (2) Return a sequence of embeddings of the sentences.\n",
    "        Download the glove vectors from here. \n",
    "        https://nlp.stanford.edu/data/glove.6B.zip\n",
    "        Handle unknown words by using zero vectors\n",
    "        \"\"\"\n",
    "        #TODO Put your code here. \n",
    "        ###########################################################################\n",
    "       \n",
    "        ###########################################################################\n",
    "    \n",
    "\n",
    "    def encode_with_openai(\n",
    "        sentences: List[str], \n",
    "        model: str = 'text-embedding-3-small',\n",
    "        api_key: Optional[str] = None,\n",
    "        batch_size: int = 100\n",
    "    ) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Encodes sentences using OpenAI's embedding API.\n",
    "        \n",
    "        # Inputs:\n",
    "            - sentences (List[str]): A list of sentences to encode.\n",
    "            - model (str): OpenAI model name. Options:\n",
    "                * 'text-embedding-3-small' (1536 dims, $0.02/1M tokens) - RECOMMENDED\n",
    "                * 'text-embedding-3-large' (3072 dims, $0.13/1M tokens)\n",
    "                * 'text-embedding-ada-002' (1536 dims, legacy)\n",
    "            - api_key (str, optional): OpenAI API key. If None, reads from OPENAI_API_KEY env variable\n",
    "            - batch_size (int): Number of sentences to encode per API call (max 2048)\n",
    "            \n",
    "        Instructions:\n",
    "        - Implement batched encoding with error handling\n",
    "        - Add rate limiting (sleep between batches)\n",
    "        \n",
    "        Expected Cost for this Assignment:\n",
    "        - ~4,000 texts (320 queries + 3,600 documents)\n",
    "        - text-embedding-3-small: ~$0.08-0.10 per student\n",
    "        - text-embedding-3-large: ~$0.50-0.65 per student\n",
    "        \n",
    "        Tips:\n",
    "        - Use try-except for API errors\n",
    "        - Implement retry logic with exponential backoff\n",
    "        - Cache embeddings to avoid re-encoding\n",
    "        - Monitor your usage at: https://platform.openai.com/usage\n",
    "        \"\"\"\n",
    "        #TODO Put your code here.\n",
    "        ###########################################################################\n",
    "        \n",
    "        ###########################################################################\n",
    "        raise NotImplementedError(\"Task 1.5 (OpenAI) not implemented yet\")\n",
    "\n",
    "    #Task 2: Calculate Cosine Similarity and Rank Documents (20 Pts)\n",
    "    \n",
    "    def rank_documents(self, encoding_method: str = 'sentence_transformer') -> None:\n",
    "        \"\"\"\n",
    "         # Inputs:\n",
    "            - encoding_method (str): The method used for encoding queries/documents. \n",
    "                             Options: ['glove', 'sentence_transformer'].\n",
    "\n",
    "        # Output:\n",
    "            - None (updates self.query_id_to_ranked_doc_ids with ranked document IDs).\n",
    "    \n",
    "        (1) Compute cosine similarity between each document and the query\n",
    "        (2) Rank documents for each query and save the results in a dictionary \"query_id_to_ranked_doc_ids\" \n",
    "            This will be used in \"mean_average_precision\"\n",
    "            Example format {2: [125, 673], 35: [900, 822]}\n",
    "        \"\"\"\n",
    "        if encoding_method == 'glove':\n",
    "            # Note: Ensure \"glove.6B.50d.txt\" is downloaded and in the local directory\n",
    "            query_embeddings = self.encode_with_glove(\"glove.6B.50d.txt\", self.queries)\n",
    "            document_embeddings = self.encode_with_glove(\"glove.6B.50d.txt\", self.documents)\n",
    "        elif encoding_method == 'sentence_transformer':\n",
    "            query_embeddings = self.model.encode(self.queries)\n",
    "            document_embeddings = self.model.encode(self.documents)\n",
    "        elif encoding_method == 'openai':\n",
    "            # Use environment variable or prompt for API key\n",
    "            query_embeddings = self.encode_with_openai(self.queries)\n",
    "            document_embeddings = self.encode_with_openai(self.documents)\n",
    "        else:\n",
    "            raise ValueError(\"Invalid encoding method. Choose 'glove' or 'sentence_transformer'.\")\n",
    "        \n",
    "        \n",
    "        #TODO Put your code here.\n",
    "        ###########################################################################\n",
    "         # define a dictionary to store the ranked documents for each query\n",
    "        self.query_id_to_ranked_doc_ids = {}\n",
    "      \n",
    "        ###########################################################################\n",
    "\n",
    "    @staticmethod\n",
    "    def average_precision(relevant_docs: list[str], candidate_docs: list[str]) -> float:\n",
    "        \"\"\"\n",
    "        # Inputs:\n",
    "            - relevant_docs (list[str]): A list of document IDs that are relevant to the query.\n",
    "            - candidate_docs (list[str]): A list of document IDs ranked by the model.\n",
    "\n",
    "        # Output:\n",
    "            - float: The average precision score\n",
    "    \n",
    "        Compute average precision for a single query.\n",
    "        \"\"\"\n",
    "        y_true = [1 if doc_id in relevant_docs else 0 for doc_id in candidate_docs]\n",
    "        precisions = [np.mean(y_true[:k+1]) for k in range(len(y_true)) if y_true[k]]\n",
    "        return np.mean(precisions) if precisions else 0\n",
    "\n",
    "    #Task 3: Calculate Evaluate System Performance (10 Pts)\n",
    "    \n",
    "    def mean_average_precision(self) -> float:\n",
    "        \"\"\"\n",
    "        # Inputs:\n",
    "            - None (uses ranked documents stored in self.query_id_to_ranked_doc_ids).\n",
    "\n",
    "        # Output:\n",
    "            - float: The MAP score, computed as the mean of all average precision scores.\n",
    "    \n",
    "        (1) Compute mean average precision for all queries using the \"average_precision\" function.\n",
    "        (2) Compute the mean of all average precision scores\n",
    "        Return the mean average precision score\n",
    "        \n",
    "        reference: https://www.evidentlyai.com/ranking-metrics/mean-average-precision-map\n",
    "        https://towardsdatascience.com/map-mean-average-precision-might-confuse-you-5956f1bfa9e2\n",
    "        \"\"\"\n",
    "         #TODO Put your code here. \n",
    "        ###########################################################################\n",
    "        \n",
    "        ###########################################################################\n",
    "    \n",
    "    #Task 4: Ranking the Top 10 Documents based on Similarity Scores (10 Pts)\n",
    "\n",
    "    def show_ranking_documents(self, encoding_method: str, example_query: str) -> None:\n",
    "                \n",
    "        \"\"\"\n",
    "        # Inputs:\n",
    "            - example_query (str): A query string for which top-ranked documents should be displayed.\n",
    "\n",
    "        # Output:\n",
    "            - None (prints the ranked documents along with similarity scores).\n",
    "        \n",
    "        (1) rank documents with given query with cosine similarity scores\n",
    "        (2) prints the top 10 results along with its similarity score.\n",
    "        \n",
    "        \"\"\"\n",
    "        #TODO Put your code here. \n",
    "\n",
    "        ###########################################################################\n",
    "      \n",
    "        # 1. Encode the single query based on the method\n",
    "        # 2. Reshape check: Ensure query_embedding is (1, n_features)\n",
    "        # 3. Calculate scores\n",
    "        \n",
    "        \n",
    "        ###########################################################################\n",
    "      \n",
    "    #Task 5:Fine tune the sentence transformer model (25 Pts)\n",
    "    # Students are not graded on achieving a high MAP score. \n",
    "    # The key is to show understanding, experimentation, and thoughtful analysis.\n",
    "    \n",
    "    def fine_tune_model(self, batch_size: int = 32, num_epochs: int = 3, save_model_path: str = \"finetuned_senBERT\") -> None:\n",
    "\n",
    "        \"\"\"\n",
    "        Fine-tunes the model using MultipleNegativesRankingLoss.\n",
    "        (1) Prepare training examples from `self.prepare_training_examples()`\n",
    "        (2) Experiment with [anchor, positive] vs [anchor, positive, negative]\n",
    "        (3) Define a loss function (`MultipleNegativesRankingLoss`)\n",
    "        (4) Freeze all model layers except the final layers\n",
    "        (5) Train the model with the specified learning rate\n",
    "        (6) Save the fine-tuned model\n",
    "        \"\"\"\n",
    "        #TODO Put your code here.\n",
    "        ###########################################################################\n",
    "\n",
    "        ###########################################################################\n",
    "\n",
    "    # Take a careful look into how the training set is created\n",
    "    def prepare_training_examples(self) -> list[InputExample]:\n",
    "\n",
    "        \"\"\"\n",
    "        Prepares training examples from the training data.\n",
    "        # Inputs:\n",
    "            - None (uses self.train_query_id_to_relevant_doc_ids to create training pairs).\n",
    "\n",
    "         # Output:\n",
    "            Output: - list[InputExample]: A list of training samples containing [anchor, positive] or [anchor, positive, negative].\n",
    "            \n",
    "        \"\"\"\n",
    "        train_examples = []\n",
    "        for qid, doc_ids in self.train_query_id_to_relevant_doc_ids.items():\n",
    "            for doc_id in doc_ids:\n",
    "                anchor = self.query_id_to_text[qid]\n",
    "                positive = self.document_id_to_text[doc_id]\n",
    "                # TODO: Select random negative examples that are not relevant to the query.\n",
    "                # TODO: Create list[InputExample] of type [anchor, positive, negative]\n",
    "                \n",
    "                train_examples.append(InputExample(texts=[anchor, positive]))\n",
    "\n",
    "        return train_examples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model with the medical dataset (nfcorpus)\n",
    "model = TextSimilarityModel(\"BeIR/nfcorpus\", \"BeIR/nfcorpus-qrels\")\n",
    "\n",
    "# Evaluate using the default Sentence Transformer\n",
    "print(\"Ranking with sentence_transformer...\")\n",
    "model.rank_documents(encoding_method='sentence_transformer')\n",
    "sbert_map = model.mean_average_precision()\n",
    "print(\"SBERT Mean Average Precision:\", sbert_map)\n",
    "\n",
    "# Evaluate using GloVe (requires 'glove.6B.50d.txt' in your directory)\n",
    "print(\"\\nRanking with glove...\")\n",
    "model.rank_documents(encoding_method='glove')\n",
    "glove_map = model.mean_average_precision()\n",
    "print(\"GloVe Mean Average Precision:\", glove_map)\n",
    "\n",
    "# Qualitative test: Show actual document text for a sample query\n",
    "model.show_ranking_documents(\"glove\",\"Breast Cancer Cells Feed on Cholesterol\")\n",
    "model.show_ranking_documents(\"sentence_transformer\", \"Breast Cancer Cells Feed on Cholesterol\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nRanking with openai...\")\n",
    "model.rank_documents(encoding_method='openai')\n",
    "openai_map = model.mean_average_precision()\n",
    "print(\"openai Mean Average Precision:\", openai_map)\n",
    "\n",
    "model.show_ranking_documents(\"openai\",\"Breast Cancer Cells Feed on Cholesterol\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finetune all-MiniLM-L6-v2 sentence transformer model\n",
    "model.fine_tune_model(batch_size=3, num_epochs=2, save_model_path=\"finetuned_senBERT_train_v2\")  # Adjust batch size and epochs as needed\n",
    "\n",
    "model.rank_documents()\n",
    "map_score = model.mean_average_precision()\n",
    "print(\"Mean Average Precision:\", map_score)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
